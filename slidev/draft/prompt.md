# 前提
データ分析コンペにAIエージェントを活用することを題材とした勉強会に登壇するための資料を作ります。
この発表では、従来難しかった「データサイエンティストと同じように、LLMに実際にデータを触ってもらいながら分析を進めてもらう」という課題を、MCPサーバを用いて解決できそうだという研究成果を話します。
以下は、スライド構成の原案です。

# 原案
1. 自己紹介
    1. 会社紹介
    2. 万年Kaggle Expert
    3. 自己紹介スライドからもってくる
2. 目次
3. コンペ*生成AIの活用状況
    1. 問題設定やデータを説明してもらう
    2. 仮説・アイディアを出してもらう　→　ここに注目！
    3. 関連する論文を探してもらう
    4. アイディアを実装してもらう
    5. バグの原因を探してもらう
    6. ベースラインを組んでもらう
    - 「実際にデータを触って分析してもらう」のは難しい？
4. 仮説・アイディアを考えるプロセス
    1. EDA型
        1. 生データを見たり、探索的にデータ加工&集約して結果を眺める　←ここがむずい
        2. 違和感などに気づく（妙だな…）
        3. 深掘りする
        4. 繰り返す
    2. 仮説駆動型
        1. 問題設計、経験などから仮説を思いつく
        2. データを触って深掘り&可視化する　←ここがむずい
        3. 結果を眺めて結論する
        4. 繰り返す
5. LLMに（チャットで）データを分析させる際の課題
    1. コードは書けても、その出力を再入力するのが大変
        1. 人間が実行して、出力をファイルにして添付して…
    2. データを眺めながら仮説を固めてほしい
6. LLMにデータを分析してもらうには？
    1. 可視化を行う関数を書く　←できる
    2. 結果をファイル出力する　←できる
    3. ファイル(csv, png)を読み込む　←できる
    4. 読み込んだ結果を解釈する　←できる
    5. 繰り返す　←できる
    
    →個別には全部できるんだから、何とかなるんじゃね？？
    
7. やってみました
    1. CLIエージェントとMCPサーバを活用
    2. kaggleの[干ばつ予測データセット](https://www.kaggle.com/datasets/cdminix/us-drought-meteorological-data)を題材にしました
    3. githubで公開しています（要リンク）
8. データセットの説明
    1. 対象データセットの各データ説明、target変数と評価指標の説明
9. MCPサーバとは？
    1. 電卓みたいなもん
        1. LLM（と我々）は暗算が苦手。でもツールとして電卓を渡してあげればいい感じになるよね？
10. システム構成
    1. 概念図
        1. CLIエージェント
            1. Claude Code
            2. Gemini CLI
        2. MCPサーバ（テーブルで書く）
            1. data_information
                1. list_available_data
                    1. 利用可能なデータ群
                2. get_data_description
                    1. 各データの概要説明md
                3. get_join_keys_info
                    1. 各データの結合構造を説明したmd
                4. get_problem_formulation
                    1. 問題設計概要md
                5. データのスキーマや列定義情報
            2. analysis_executor
                1. get_data_sample
                    1. 各データのheadとtailを取得
                2. get_data_summary
                    1. 各データの統計要約情報を取得
                3. execute_timeseries_analysis
                    1. メインの時系列データに対し、要求された関数を実行
                4. execute_soil_analysis
                    1. 土壌データに対し、要求された関数を実行
                5. execute_all_data_analysis
                    1. すべてのデータに対し、要求された関数を実行
            3. notebook_writer
                1. add_cell_to_notebook
                    1. jupyter notebookにコードと分析結果を追加
11. MCPツール定義
    1. 各関数定義のスニペットを表示して説明
12. EDA動作画面スクショ、notebook見せる
13. まとめ
    1. データを触りながら自律的にEDAをしてもらえるようになったよ
        1. 使ってもらったMCPサーバのツールたち
            1. データ情報を取得できるツール
            2. 関数定義を渡して実行できるツール
            3. notebookにセルを書き込むツール
    2. 今回はテーブルデータだけど、画像、自然言語にも拡張できそうだよ
    3. atma, kaggle楽しみましょう！

# 添削
視聴者はデータサイエンスの知識がありますが、MCPについてはふんわりした理解しかない人が多いかもしれません。まず、視聴者の立場に立って、この構成が聞きやすいかどうかといった観点で評価してください。

# yaml生成
この原案を、具体的な各スライド構成にyaml形式でまとめてください。このyamlを見てスライド作成作業がスムーズに進むような粒度で、必要な情報をすべて含めてください。作業していく中で、不明瞭な点が出てきたら、仮置きせず、私に必ず確認してください。例外として、自己紹介スライドのみは仮置きのままでOKです。また、スライドはできるだけ文字が多くならないようにし、視聴者が最後まで疲れずに楽しめるような構成にしてください。スライド作成に必要な資料はすべて添付してあります。

{
    "context": [
        "agent/mcp/components",
        "GEMINI.md,
    ]
}

# 再添削
以下はスライド構成の草案です。視聴者はデータサイエンスの知識がありますが、MCPについてはふんわりした理解しかない人が多いかもしれません。視聴者の立場に立って、この発表の改善点があれば教えてください。

{
    "context": [
        "/work/slidev/draft/draft.yaml",
    ]
}

# slidev翻訳
slidevを使ってプレゼンスライドを作ります。 @slidev/slides.md がスライド本体です。各ページは @slidev/pages 配下にそれぞれ作成してください。原稿は @slidev/draft/draft.yaml です。スライドサンプルは @document/slidev/sample/slides.md , @document/slidev/sample/pages/imported-slides.md にあるので、まずこれを通読してください。slidevの仕様は @document/slidev 配下にあるので、必要に応じて参照してください。原稿の内容を忠実に反映するように作成してください。レイアウトなどについては、より分かりやすくするために修正を加えても構いません。画像は、必ずアスペクト比を保って使用してください。
スライドを一枚作成するたびに、必ず @slidev/draft/draft.yaml を再度読み込んで、今作るべきスライドの内容を深く確認してください。